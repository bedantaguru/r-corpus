<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Chinese text handling • corpus</title>
<!-- jquery --><script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">
<!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../jquery.sticky-kit.min.js"></script><script src="../pkgdown.js"></script><!-- mathjax --><script src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]--><!-- Google analytics --><script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-4636081-3', 'auto');
  ga('send', 'pageview');

</script>
</head>
<body>
    <div class="container template-vignette">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="../index.html">corpus</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="..//index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../articles/corpus.html">Get Started</a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/chinese.html">Chinese text handling</a>
    </li>
    <li>
      <a href="../articles/gender.html">Finding gendered words</a>
    </li>
    <li>
      <a href="../articles/textdata.html">Text data in Corpus and other packages</a>
    </li>
    <li>
      <a href="../articles/unicode.html">Unicode: Emoji, accents, and international text</a>
    </li>
  </ul>
</li>
<li>
  <a href="../news/index.html">News</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right"></ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9">
    <div class="page-header toc-ignore">
      <h1>Chinese text handling</h1>
            
          </div>

    
    
<div class="contents">
<div id="overview" class="section level2">
<h2 class="hasAnchor">
<a href="#overview" class="anchor"></a>Overview</h2>
<p>This vignette shows how to work with Chinese language materials using the corpus package. It’s based on Haiyan Wang’s <a href="https://github.com/ropensci/textworkshop17/tree/master/demos/chineseDemo">rOpenSci demo</a> and assumes you have <code>httr</code>, <code>stringi</code>, and <code>wordcloud</code> installed.</p>
<p>We’ll start by loading the package and setting a seed to ensure reproducible results</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(<span class="st">"corpus"</span>)
<span class="kw">set.seed</span>(<span class="dv">100</span>)</code></pre></div>
</div>
<div id="documents-and-stopwords" class="section level2">
<h2 class="hasAnchor">
<a href="#documents-and-stopwords" class="anchor"></a>Documents and stopwords</h2>
<p>First download a stop word list suitable for Chinese, the Baidu stop words</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">cstops &lt;-<span class="st"> "https://raw.githubusercontent.com/ropensci/textworkshop17/master/demos/chineseDemo/ChineseStopWords.txt"</span>
csw &lt;-<span class="st"> </span><span class="kw">paste</span>(<span class="kw">readLines</span>(cstops, <span class="dt">encoding =</span> <span class="st">"UTF-8"</span>), <span class="dt">collapse =</span> <span class="st">"</span><span class="ch">\n</span><span class="st">"</span>) <span class="co"># download</span>
csw &lt;-<span class="st"> </span><span class="kw">gsub</span>(<span class="st">"</span><span class="ch">\\</span><span class="st">s"</span>, <span class="st">""</span>, csw)           <span class="co"># remove whitespace</span>
stop_words &lt;-<span class="st"> </span><span class="kw">strsplit</span>(csw, <span class="st">","</span>)[[<span class="dv">1</span>]] <span class="co"># extract the comma-separated words</span></code></pre></div>
<p>Next, download some demonstration documents. These are in plain text format, encoded in UTF-8.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">gov_reports &lt;-<span class="st"> "https://api.github.com/repos/ropensci/textworkshop17/contents/demos/chineseDemo/govReports"</span>
raw &lt;-<span class="st"> </span>httr<span class="op">::</span><span class="kw"><a href="http://www.rdocumentation.org/packages/httr/topics/GET">GET</a></span>(gov_reports)
paths &lt;-<span class="st"> </span><span class="kw">sapply</span>(httr<span class="op">::</span><span class="kw"><a href="http://www.rdocumentation.org/packages/httr/topics/content">content</a></span>(raw), <span class="cf">function</span>(x) x<span class="op">$</span>path)
names &lt;-<span class="st"> </span>tools<span class="op">::</span><span class="kw"><a href="http://www.rdocumentation.org/packages/tools/topics/fileutils">file_path_sans_ext</a></span>(<span class="kw">basename</span>(paths))
urls &lt;-<span class="st"> </span><span class="kw">sapply</span>(httr<span class="op">::</span><span class="kw"><a href="http://www.rdocumentation.org/packages/httr/topics/content">content</a></span>(raw), <span class="cf">function</span>(x) x<span class="op">$</span>download_url)
text &lt;-<span class="st"> </span><span class="kw">sapply</span>(urls, <span class="cf">function</span>(url) <span class="kw">paste</span>(<span class="kw">readLines</span>(url, <span class="dt">warn =</span> <span class="ot">FALSE</span>,
                                                   <span class="dt">encoding =</span> <span class="st">"UTF-8"</span>),
                                         <span class="dt">collapse =</span> <span class="st">"</span><span class="ch">\n</span><span class="st">"</span>))
<span class="kw">names</span>(text) &lt;-<span class="st"> </span>names</code></pre></div>
</div>
<div id="tokenization" class="section level2">
<h2 class="hasAnchor">
<a href="#tokenization" class="anchor"></a>Tokenization</h2>
<p>Corpus does not know how to tokenize languages with no spaces between words. Fortunately, the ICU library (used internally by the <code>stringi</code> package) does, by using a dictionary of words along with information about their relative usage rates.</p>
<p>We use <code>stringi</code>’s tokenizer, collect a dictionary of the word types, and then manually insert zero-width spaces between tokens.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">toks &lt;-<span class="st"> </span>stringi<span class="op">::</span><span class="kw"><a href="http://www.rdocumentation.org/packages/stringi/topics/stri_split_boundaries">stri_split_boundaries</a></span>(text, <span class="dt">type =</span> <span class="st">"word"</span>)
dict &lt;-<span class="st"> </span><span class="kw">unique</span>(<span class="kw">c</span>(toks, <span class="dt">recursive =</span> <span class="ot">TRUE</span>)) <span class="co"># unique words</span>
text2 &lt;-<span class="st"> </span><span class="kw">sapply</span>(toks, paste, <span class="dt">collapse =</span> <span class="st">"\u200b"</span>)</code></pre></div>
<p>and put the input text in a data frame for convenient analysis</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">data &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">name =</span> names, <span class="dt">text =</span> <span class="kw"><a href="../reference/corpus_text.html">as_corpus_text</a></span>(text2),
                   <span class="dt">stringsAsFactors =</span> <span class="ot">FALSE</span>)</code></pre></div>
<p>We then specify a token filter to determine what is counted by other corpus functions. Here we set <code>combine = dict</code> so that multi-word tokens get treated as single entities</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">f &lt;-<span class="st"> </span><span class="kw"><a href="../reference/text_filter.html">text_filter</a></span>(<span class="dt">drop_punct =</span> <span class="ot">TRUE</span>, <span class="dt">drop =</span> stop_words, <span class="dt">combine =</span> dict)
(<span class="kw"><a href="../reference/text_filter.html">text_filter</a></span>(data) &lt;-<span class="st"> </span>f) <span class="co"># set the text column's filter</span></code></pre></div>
<pre><code>Text filter with the following options:

    map_case: TRUE
    map_quote: TRUE
    remove_ignorable: TRUE
    stemmer: NULL
    stem_dropped: FALSE
    stem_except: NULL
    combine:  chr [1:12033] "\n" "1954" "年" "政府" "工作" "报告" ...
    drop_letter: FALSE
    drop_number: FALSE
    drop_punct: TRUE
    drop_symbol: FALSE
    drop:  chr [1:717] "按" "按照" "俺" "俺们" "阿" "别" "别人" ...
    drop_except: NULL
    sent_crlf: FALSE
    sent_suppress:  chr [1:155] "A." "A.D." "a.m." "A.M." "A.S." ...</code></pre>
</div>
<div id="document-statistics" class="section level2">
<h2 class="hasAnchor">
<a href="#document-statistics" class="anchor"></a>Document statistics</h2>
<p>We can now compute type, token, and sentence counts</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(<span class="kw">data.frame</span>(<span class="dt">text =</span> data<span class="op">$</span>name,
                <span class="dt">types =</span> <span class="kw"><a href="../reference/text_types.html">text_ntype</a></span>(data),
                <span class="dt">tokens =</span> <span class="kw"><a href="../reference/text_tokens.html">text_ntoken</a></span>(data),
                <span class="dt">sentences =</span> <span class="kw"><a href="../reference/text_split.html">text_nsentence</a></span>(data)))</code></pre></div>
<pre><code>                     text types tokens sentences
1 1954政府工作报告_周恩来  2023   8694       453
2 1955政府工作报告_李富春  2780  21079       981
3 1956政府工作报告_李先念  1342   9079       495
4 1957政府工作报告_周恩来  2334  13009       704
5 1958政府工作报告_薄一波  1973   9347       412
6 1959政府工作报告_周恩来  2263  11640       577</code></pre>
<p>and examine term frequencies</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(stats &lt;-<span class="st"> </span><span class="kw"><a href="../reference/term_stats.html">term_stats</a></span>(data))</code></pre></div>
<pre><code>   term count support
1  发展  5627      49
2  经济  5036      49
3  社会  4255      49
4  建设  4248      49
5  人民  2897      49
6  主义  2817      49
7  工作  2642      49
8  企业  2627      49
9  国家  2595      49
10 加强  2438      49
11 生产  2407      49
12 年    2021      49
13 我国  1999      49
14 提高  1947      49
15 中    1860      49
16 增长  1800      49
17 化    1740      49
18 继续  1670      49
19 技术  1586      49
20 工业  1580      49
⋮  (11612 rows total)</code></pre>
<p>These operations all use the <code><a href="../reference/text_filter.html">text_filter(data)</a></code> value we set above to determine the token and sentence boundaries.</p>
</div>
<div id="visualization" class="section level2">
<h2 class="hasAnchor">
<a href="#visualization" class="anchor"></a>Visualization</h2>
<p>We can visualize word frequencies with a wordcloud. You may want to use a font suitable for Chinese (‘STSong’ is a good choice for Mac users). We switch to this font, create the wordcloud, then switch back.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">font_family &lt;-<span class="st"> </span><span class="kw">par</span>(<span class="st">"family"</span>) <span class="co"># the previous font family</span>
<span class="kw">par</span>(<span class="dt">family =</span> <span class="st">"STSong"</span>) <span class="co"># change to a nice Chinese font</span>
<span class="kw">with</span>(stats, {
    wordcloud<span class="op">::</span><span class="kw"><a href="http://www.rdocumentation.org/packages/wordcloud/topics/wordcloud">wordcloud</a></span>(term, count, <span class="dt">min.freq =</span> <span class="dv">500</span>,
                         <span class="dt">random.order =</span> <span class="ot">FALSE</span>, <span class="dt">rot.per =</span> <span class="fl">0.25</span>,
                         <span class="dt">colors =</span> RColorBrewer<span class="op">::</span><span class="kw"><a href="http://www.rdocumentation.org/packages/RColorBrewer/topics/ColorBrewer">brewer.pal</a></span>(<span class="dv">8</span>, <span class="st">"Dark2"</span>))
})</code></pre></div>
<div class="figure">
<img src="chinese-wordcloud-1.png" alt="Word cloud"><p class="caption">Word cloud</p>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">par</span>(<span class="dt">family =</span> font_family) <span class="co"># switch the font back</span></code></pre></div>
</div>
<div id="co-occurrences" class="section level2">
<h2 class="hasAnchor">
<a href="#co-occurrences" class="anchor"></a>Co-occurrences</h2>
<p>Here are the terms that show up in sentences containing a particular term</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sents &lt;-<span class="st"> </span><span class="kw"><a href="../reference/text_split.html">text_split</a></span>(data) <span class="co"># split text into sentences</span>
subset &lt;-<span class="st"> </span><span class="kw"><a href="../reference/text_locate.html">text_subset</a></span>(sents, <span class="st">'\u6539\u9769'</span>) <span class="co"># select those with the term</span>
<span class="kw"><a href="../reference/term_stats.html">term_stats</a></span>(subset) <span class="co"># count the word occurrences</span></code></pre></div>
<pre><code>   term count support
1  改革  2931    2457
2  发展   866     652
3  体制   768     649
4  经济  1016     639
5  推进   522     491
6  深化   473     469
7  社会   664     464
8  建设   513     391
9  制度   452     364
10 开放   389     353
11 企业   489     339
12 工作   301     268
13 积极   262     252
14 继续   260     251
15 管理   281     249
16 进行   239     232
17 加快   230     225
18 化     261     224
19 加强   248     224
20 主义   275     221
⋮  (3888 rows total)</code></pre>
<p>The first term is the search query. It appears 2931 times in the corpus, in 2457 different sentences. The second term in the list appears in 652 of 2457 sentences containing the search term. (I don’t speak Chinese, but Google translate tells me that the search term is “reform”, and the second and third items in the list are “development” and “system”.)</p>
</div>
<div id="keyword-in-context" class="section level2">
<h2 class="hasAnchor">
<a href="#keyword-in-context" class="anchor"></a>Keyword in context</h2>
<p>Finally, here’s how we might show terms in their local context</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/text_locate.html">text_locate</a></span>(data, <span class="st">"\u6027"</span>)</code></pre></div>
<pre><code>   text            before            instance             after            
1  1     …业方面的重要问题之一是计划    性    不足。我们现在还有许多计划不…
2  1     …技术和提高劳动生产率的积极    性    ，对于发展经济建设很有害，因…
3  1     …分表现了人民群众的政治积极    性    和政治觉悟的提高，充分表现了…
4  1     …器、氢武器和其他大规模毁灭    性    武器的愿望必须满足。这些都是…
5  2     …众在劳动战线上的高度的积极    性    和创造性，依靠全国人民在改革…
6  2     …战线上的高度的积极性和创造    性    ，依靠全国人民在改革土地制度…
7  2     …，已经分得了土地，生产积极    性    很高，何必实行合作化呢？我们…
8  2     …觉悟，充分地发挥群众的积极    性    和创造性，提高劳动生产率。\n…
9  2     …分地发挥群众的积极性和创造    性    ，提高劳动生产率。\n\n　　我…
10 2     …必须照顾单干农户的生产积极    性    ，给单干农户以积极的帮助和领…
11 2     …重要办法。国家从缩减非生产    性    建设的支出和行政机关的经费等…
12 2     …，更重要的是发扬地方的积极    性    ，加强地方党政机关对农业的领…
13 2     …策，提高农民群众的生产积极    性    ，保证这个计划的实现。地方的…
14 2     …，刺激和发挥农民的经营积极    性    。\n\n　　有些农村的地方国家…
15 2     …设以后，为了加强生产的计划    性    ，对许多重要原料，有的由国家…
16 2     …进一步地提高农民的增产积极    性    ，促进农业生产的发展。这对于…
17 2     …高农民特别是中农的生产积极    性    。\n\n　　关于粮食的计划收购…
18 2     …害关系，从而更加积极地创造    性    地参加国家建设。\n\n　　人们…
19 2     …，我们必须大大地削减非生产    性    建设的支出。几年来在非生产性…
20 2     …年计划中，工业部门的非生产    性    投资只占全部投资的百分之十四…
⋮  (1341 rows total)</code></pre>
<p><em>Note: the alignment looks bad here because the Chinese characters have widths between 1 and 2 spaces each. The spacing in the table is set assuming that Chinese characters take exactly 2 spaces each. If you know how to set the font to make the widths agree, please contact me.</em></p>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
        <div id="tocnav">
      <h2 class="hasAnchor">
<a href="#tocnav" class="anchor"></a>Contents</h2>
      <ul class="nav nav-pills nav-stacked">
<li><a href="#overview">Overview</a></li>
      <li><a href="#documents-and-stopwords">Documents and stopwords</a></li>
      <li><a href="#tokenization">Tokenization</a></li>
      <li><a href="#document-statistics">Document statistics</a></li>
      <li><a href="#visualization">Visualization</a></li>
      <li><a href="#co-occurrences">Co-occurrences</a></li>
      <li><a href="#keyword-in-context">Keyword in context</a></li>
      </ul>
</div>
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by Patrick O. Perry.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://hadley.github.io/pkgdown/">pkgdown</a>.</p>
</div>

      </footer>
</div>

  </body>
</html>
